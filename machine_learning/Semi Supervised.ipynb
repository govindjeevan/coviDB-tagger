{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "behind-jumping",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "liked-article",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.24.2-cp38-cp38-manylinux2010_x86_64.whl (24.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.9 MB 18.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.13.3 in /opt/conda/lib/python3.8/site-packages (from scikit-learn) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/conda/lib/python3.8/site-packages (from scikit-learn) (0.15.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /opt/conda/lib/python3.8/site-packages (from scikit-learn) (1.5.2)\n",
      "Installing collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.23.2\n",
      "    Uninstalling scikit-learn-0.23.2:\n",
      "      Successfully uninstalled scikit-learn-0.23.2\n",
      "Successfully installed scikit-learn-0.24.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "covered-advisory",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_tags = pd.read_csv(\"articles_tags.csv\")\n",
    "article_text = pd.read_csv(\"../resources/articles_text.csv\")\n",
    "article_tags= article_tags.set_index(\"Resource URL\")\n",
    "article_text = article_text.set_index(\"Resource URL\")\n",
    "article_text = article_text[~article_text.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "super-lecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in article_text.index:\n",
    "    article_text.loc[i, \"tech_tag\"] =  article_tags.loc[i][\"Technical (Y/N)\"][0]\n",
    "    if article_text.loc[i, \"tech_tag\"] not in [\"Y\", \"N\"]:\n",
    "        article_text.loc[i, \"tech_tag\"]  = \"M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "partial-soccer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pandas/core/indexing.py:1783: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n",
      "/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py:4162: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "data = (article_text[(article_text[\"tech_tag\"]==\"Y\") | (article_text[\"tech_tag\"]==\"N\")])\n",
    "data_src = data\n",
    "data_src = data_src[[\"Resource Title\", \"text\", \"tech_tag\"]]\n",
    "data_src.loc[:, \"text\"] =  data_src[\"Resource Title\"] + \" \" +data_src[\"text\"]\n",
    "data_src.loc[:, \"tech_tag\"] = data_src[\"tech_tag\"].map({\"N\": 0, \"Y\":1})\n",
    "data_src.drop(\"Resource Title\", axis=1, inplace=True)\n",
    "data_src = data_src.dropna().reset_index(drop=True)\n",
    "data=data_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "rising-preview",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pandas/core/indexing.py:1783: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n",
      "/opt/conda/lib/python3.8/site-packages/pandas/core/indexing.py:1596: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/opt/conda/lib/python3.8/site-packages/pandas/core/indexing.py:1765: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n",
      "/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py:4162: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "unlabelled_data = (article_text[(article_text[\"tech_tag\"]!=\"Y\") & (article_text[\"tech_tag\"]!=\"N\")])\n",
    "data_src = unlabelled_data\n",
    "data_src = data_src[[\"Resource Title\", \"text\"]]\n",
    "data_src.loc[:, \"text\"] =  data_src[\"Resource Title\"] + \" \" +data_src[\"text\"]\n",
    "data_src.loc[:, \"tech_tag\"] = -1\n",
    "data_src.drop(\"Resource Title\", axis=1, inplace=True)\n",
    "data_src = data_src.dropna().reset_index(drop=True)\n",
    "unlabelled_data=data_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "infectious-craft",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-25-467913dd0a2f>, line 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-25-467913dd0a2f>\"\u001b[0;36m, line \u001b[0;32m26\u001b[0m\n\u001b[0;31m    ('clf', MLPClassifier(alpha=1, max_iter=1000), verbose=True),\u001b[0m\n\u001b[0m                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.semi_supervised import SelfTrainingClassifier\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Parameters\n",
    "sdg_params = dict(alpha=1e-5, penalty='l2', loss='log')\n",
    "vectorizer_params = dict(ngram_range=(1, 2), min_df=5, max_df=0.8)\n",
    "\n",
    "# Supervised Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(**vectorizer_params)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MLPClassifier(alpha=1, max_iter=1000), verbose=True),\n",
    "])\n",
    "# SelfTraining Pipeline\n",
    "st_pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(**vectorizer_params)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SelfTrainingClassifier(MLPClassifier(alpha=1, max_iter=1000), verbose=True)),\n",
    "])\n",
    "# LabelSpreading Pipeline\n",
    "ls_pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(**vectorizer_params)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    # LabelSpreading does not support dense matrices\n",
    "    ('todense', FunctionTransformer(lambda x: x.todense())),\n",
    "    ('clf', LabelSpreading()),\n",
    "])\n",
    "\n",
    "\n",
    "def eval_and_print_metrics(clf, X_train, y_train, X_test, y_test):\n",
    "    print(\"Number of training samples:\", len(X_train))\n",
    "    print(\"Unlabeled samples in training set:\",\n",
    "          sum(1 for x in y_train if x == -1))\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print ('Accuracy Score :',accuracy_score(y_test, y_pred))\n",
    "    print(\"Micro-averaged F1 score on test set: \"\n",
    "          \"%0.3f\" % f1_score(y_test, y_pred, average='micro'))\n",
    "    print(\"-\" * 10)\n",
    "    print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "valued-foster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supervised SGDClassifier on 100% of the data:\n",
      "Number of training samples: 500\n",
      "Unlabeled samples in training set: 0\n",
      "Accuracy Score : 0.918\n",
      "Micro-averaged F1 score on test set: 0.918\n",
      "----------\n",
      "\n",
      "Supervised SGDClassifier on 20% of the training data:\n",
      "Number of training samples: 97\n",
      "Unlabeled samples in training set: 0\n",
      "Accuracy Score : 0.844\n",
      "Micro-averaged F1 score on test set: 0.844\n",
      "----------\n",
      "\n",
      "SelfTrainingClassifier on 20% of the training data (rest is unlabeled):\n",
      "Number of training samples: 500\n",
      "Unlabeled samples in training set: 403\n",
      "End of iteration 1, added 225 new labels.\n",
      "End of iteration 2, added 60 new labels.\n",
      "End of iteration 3, added 17 new labels.\n",
      "End of iteration 4, added 4 new labels.\n",
      "Accuracy Score : 0.764\n",
      "Micro-averaged F1 score on test set: 0.764\n",
      "----------\n",
      "\n",
      "LabelSpreading on 20% of the data (rest is unlabeled):\n",
      "Number of training samples: 500\n",
      "Unlabeled samples in training set: 403\n",
      "Accuracy Score : 0.872\n",
      "Micro-averaged F1 score on test set: 0.872\n",
      "----------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X, y = data.text, data.tech_tag\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size = 0.5)\n",
    "\n",
    "print(\"Supervised SGDClassifier on 100% of the data:\")\n",
    "eval_and_print_metrics(pipeline, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# select a mask of 20% of the train dataset\n",
    "y_mask = np.random.rand(len(y_train)) < 0.2\n",
    "\n",
    "# X_20 and y_20 are the subset of the train dataset indicated by the mask\n",
    "X_20, y_20 = map(list, zip(*((x, y)\n",
    "                 for x, y, m in zip(X_train, y_train, y_mask) if m)))\n",
    "print(\"Supervised SGDClassifier on 20% of the training data:\")\n",
    "eval_and_print_metrics(pipeline, X_20, y_20, X_test, y_test)\n",
    "\n",
    "# set the non-masked subset to be unlabeled\n",
    "y_train[~y_mask] = -1\n",
    "print(\"SelfTrainingClassifier on 20% of the training data (rest \"\n",
    "      \"is unlabeled):\")\n",
    "eval_and_print_metrics(st_pipeline, X_train, y_train, X_test, y_test)\n",
    "\n",
    "if 'CI' not in os.environ:\n",
    "    # LabelSpreading takes too long to run in the online documentation\n",
    "    print(\"LabelSpreading on 20% of the data (rest is unlabeled):\")\n",
    "    eval_and_print_metrics(ls_pipeline, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-express",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-procurement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "molecular-report",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data.text, data.tech_tag\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bottom-missile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "rotary-approach",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train, unlabelled_data.text], ignore_index = True)\n",
    "y_train = pd.concat([y_train, unlabelled_data.tech_tag], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "freelance-consumer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1695"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "universal-premium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelSpreading on 20% of the data (rest is unlabeled):\n",
      "Number of training samples: 1695\n",
      "Unlabeled samples in training set: 1195\n",
      "Accuracy Score : 0.722\n",
      "Micro-averaged F1 score on test set: 0.722\n",
      "----------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"LabelSpreading on 20% of the data (rest is unlabeled):\")\n",
    "eval_and_print_metrics(ls_pipeline, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "instructional-movie",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelfTrainingClassifier on 20% of the training data (rest is unlabeled):\n",
      "Number of training samples: 1695\n",
      "Unlabeled samples in training set: 1195\n",
      "End of iteration 1, added 735 new labels.\n",
      "End of iteration 2, added 257 new labels.\n",
      "End of iteration 3, added 92 new labels.\n",
      "End of iteration 4, added 26 new labels.\n",
      "End of iteration 5, added 5 new labels.\n",
      "Accuracy Score : 0.838\n",
      "Micro-averaged F1 score on test set: 0.838\n",
      "----------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"SelfTrainingClassifier on 20% of the training data (rest \"\n",
    "      \"is unlabeled):\")\n",
    "eval_and_print_metrics(st_pipeline, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-flight",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
